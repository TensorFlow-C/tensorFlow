{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_cell.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMsxK6UUH4tPajLxp1cHC72",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhoujiuzhou9/tensorFlow/blob/V2/sentiment_analysis_cell.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNZQaktqHvu7",
        "outputId": "5f9bf21a-b981-4250-a75c-6af3f93cb96b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "x_train shape: (25000, 80) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n",
            "x_test shape: (25000, 80)\n",
            "Epoch 1/4\n",
            "195/195 [==============================] - 24s 41ms/step - loss: 0.6827 - accuracy: 0.5412 - val_loss: 0.5770 - val_accuracy: 0.7244\n",
            "Epoch 2/4\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.4656 - accuracy: 0.7855 - val_loss: 0.3883 - val_accuracy: 0.8320\n",
            "Epoch 3/4\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.3265 - accuracy: 0.8630 - val_loss: 0.4331 - val_accuracy: 0.8180\n",
            "Epoch 4/4\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.2479 - accuracy: 0.9012 - val_loss: 0.4412 - val_accuracy: 0.8283\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4412 - accuracy: 0.8283\n"
          ]
        }
      ],
      "source": [
        "import  os\n",
        "import  tensorflow as tf\n",
        "import  numpy as np\n",
        "from    tensorflow import keras\n",
        "from    tensorflow.keras import layers\n",
        "\n",
        "\n",
        "tf.random.set_seed(22)\n",
        "np.random.seed(22)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "assert tf.__version__.startswith('2.')\n",
        "\n",
        "batchsz = 128\n",
        "\n",
        "# the most frequest words\n",
        "total_words = 10000\n",
        "max_review_len = 80\n",
        "embedding_len = 100\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)\n",
        "# x_train:[b, 80]\n",
        "# x_test: [b, 80]\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n",
        "\n",
        "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "db_train = db_train.shuffle(1000).batch(batchsz, drop_remainder=True)\n",
        "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "db_test = db_test.batch(batchsz, drop_remainder=True)\n",
        "print('x_train shape:', x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "class MyRNN(keras.Model):\n",
        "\n",
        "    def __init__(self, units):\n",
        "        super(MyRNN, self).__init__()\n",
        "\n",
        "        # [b, 64]\n",
        "        self.state0 = [tf.zeros([batchsz, units])]\n",
        "        self.state1 = [tf.zeros([batchsz, units])]\n",
        "\n",
        "        # transform text to embedding representation\n",
        "        # [b, 80] => [b, 80, 100]\n",
        "        self.embedding = layers.Embedding(total_words, embedding_len,\n",
        "                                          input_length=max_review_len)\n",
        "\n",
        "        # [b, 80, 100] , h_dim: 64\n",
        "        # RNN: cell1 ,cell2, cell3\n",
        "        # SimpleRNN\n",
        "        self.rnn_cell0 = layers.SimpleRNNCell(units, dropout=0.5)\n",
        "        self.rnn_cell1 = layers.SimpleRNNCell(units, dropout=0.5)\n",
        "\n",
        "\n",
        "        # fc, [b, 80, 100] => [b, 64] => [b, 1]\n",
        "        self.outlayer = layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        \"\"\"\n",
        "        net(x) net(x, training=True) :train mode\n",
        "        net(x, training=False): test\n",
        "        :param inputs: [b, 80]\n",
        "        :param training:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # [b, 80]\n",
        "        x = inputs\n",
        "        # embedding: [b, 80] => [b, 80, 100]\n",
        "        x = self.embedding(x)\n",
        "        # rnn cell compute\n",
        "        # [b, 80, 100] => [b, 64]\n",
        "        state0 = self.state0\n",
        "        state1 = self.state1\n",
        "        for word in tf.unstack(x, axis=1): # word: [b, 100]\n",
        "            # h1 = x*wxh+h0*whh\n",
        "            # out0: [b, 64]\n",
        "            out0, state0 = self.rnn_cell0(word, state0, training)\n",
        "            # out1: [b, 64]\n",
        "            out1, state1 = self.rnn_cell1(out0, state1, training)\n",
        "\n",
        "        # out: [b, 64] => [b, 1]\n",
        "        x = self.outlayer(out1)\n",
        "        # p(y is pos|x)\n",
        "        prob = tf.sigmoid(x)\n",
        "\n",
        "        return prob\n",
        "\n",
        "def main():\n",
        "    units = 64\n",
        "    epochs = 4\n",
        "\n",
        "    model = MyRNN(units)\n",
        "    model.compile(optimizer = keras.optimizers.Adam(0.001),\n",
        "                  loss = tf.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(db_train, epochs=epochs, validation_data=db_test)\n",
        "\n",
        "    model.evaluate(db_test)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import  os\n",
        "import  tensorflow as tf\n",
        "import  numpy as np\n",
        "from    tensorflow import keras\n",
        "from    tensorflow.keras import layers\n",
        "\n",
        "\n",
        "tf.random.set_seed(22)\n",
        "np.random.seed(22)\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "assert tf.__version__.startswith('2.')\n",
        "\n",
        "batchsz = 128\n",
        "\n",
        "# the most frequest words\n",
        "total_words = 10000\n",
        "max_review_len = 80\n",
        "embedding_len = 100\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)\n",
        "# x_train:[b, 80]\n",
        "# x_test: [b, 80]\n",
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n",
        "\n",
        "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "db_train = db_train.shuffle(1000).batch(batchsz, drop_remainder=True)\n",
        "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "db_test = db_test.batch(batchsz, drop_remainder=True)\n",
        "print('x_train shape:', x_train.shape, tf.reduce_max(y_train), tf.reduce_min(y_train))\n",
        "print('x_test shape:', x_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "class MyRNN(keras.Model):\n",
        "\n",
        "    def __init__(self, units):\n",
        "        super(MyRNN, self).__init__()\n",
        "\n",
        "\n",
        "        # transform text to embedding representation\n",
        "        # [b, 80] => [b, 80, 100]\n",
        "        self.embedding = layers.Embedding(total_words, embedding_len,\n",
        "                                          input_length=max_review_len)\n",
        "\n",
        "        # [b, 80, 100] , h_dim: 64\n",
        "        self.rnn = keras.Sequential([\n",
        "            layers.SimpleRNN(units, dropout=0.5, return_sequences=True, unroll=True),\n",
        "            layers.SimpleRNN(units, dropout=0.5, unroll=True)\n",
        "        ])\n",
        "\n",
        "\n",
        "        # fc, [b, 80, 100] => [b, 64] => [b, 1]\n",
        "        self.outlayer = layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        \"\"\"\n",
        "        net(x) net(x, training=True) :train mode\n",
        "        net(x, training=False): test\n",
        "        :param inputs: [b, 80]\n",
        "        :param training:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # [b, 80]\n",
        "        x = inputs\n",
        "        # embedding: [b, 80] => [b, 80, 100]\n",
        "        x = self.embedding(x)\n",
        "        # rnn cell compute\n",
        "        # x: [b, 80, 100] => [b, 64]\n",
        "        x = self.rnn(x)\n",
        "\n",
        "        # out: [b, 64] => [b, 1]\n",
        "        x = self.outlayer(x)\n",
        "        # p(y is pos|x)\n",
        "        prob = tf.sigmoid(x)\n",
        "\n",
        "        return prob\n",
        "\n",
        "def main():\n",
        "    units = 64\n",
        "    epochs = 4\n",
        "\n",
        "    model = MyRNN(units)\n",
        "    model.compile(optimizer = keras.optimizers.Adam(0.001),\n",
        "                  loss = tf.losses.BinaryCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(db_train, epochs=epochs, validation_data=db_test)\n",
        "\n",
        "    model.evaluate(db_test)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiTA6AeuH7oq",
        "outputId": "a0e4e9f6-466c-4204-e27c-f268511a9b08"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (25000, 80) tf.Tensor(1, shape=(), dtype=int64) tf.Tensor(0, shape=(), dtype=int64)\n",
            "x_test shape: (25000, 80)\n",
            "Epoch 1/4\n",
            "195/195 [==============================] - 16s 43ms/step - loss: 0.6832 - accuracy: 0.5409 - val_loss: 0.5115 - val_accuracy: 0.7527\n",
            "Epoch 2/4\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.4265 - accuracy: 0.8111 - val_loss: 0.3898 - val_accuracy: 0.8321\n",
            "Epoch 3/4\n",
            "195/195 [==============================] - 6s 31ms/step - loss: 0.3184 - accuracy: 0.8692 - val_loss: 0.4185 - val_accuracy: 0.8181\n",
            "Epoch 4/4\n",
            "195/195 [==============================] - 6s 32ms/step - loss: 0.2432 - accuracy: 0.9058 - val_loss: 0.4557 - val_accuracy: 0.8261\n",
            "195/195 [==============================] - 2s 10ms/step - loss: 0.4557 - accuracy: 0.8261\n"
          ]
        }
      ]
    }
  ]
}